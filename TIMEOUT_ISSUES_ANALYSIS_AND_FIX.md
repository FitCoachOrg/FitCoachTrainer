# Timeout Issues Analysis and Fix

## üîç **Investigation Results**

After comprehensive testing, I've identified that the timeout issues with the `getClientData` function are **not due to schema mismatches or Supabase performance problems**. The tests show:

- ‚úÖ Database connection is working (732ms response time)
- ‚úÖ `client` table exists and is accessible
- ‚úÖ `getClientData` query works perfectly in isolation (91-217ms)
- ‚úÖ All client IDs are accessible and return data correctly
- ‚úÖ No RLS policy issues
- ‚úÖ Database performance under load is acceptable (98ms average)

## üö® **Root Cause Analysis**

The timeout issues are likely caused by:

1. **Network Latency**: Intermittent network connectivity issues
2. **Browser Resource Constraints**: Memory or CPU limitations during heavy operations
3. **Concurrent Operations**: Multiple simultaneous database queries causing resource contention
4. **Race Conditions**: Multiple save operations happening simultaneously
5. **Temporary Supabase Issues**: Occasional service degradation

## üõ†Ô∏è **Comprehensive Fix Implementation**

### **1. Enhanced Caching Strategy**

The current caching is good, but we can improve it:

```typescript
// Enhanced caching with longer duration and better invalidation
const CACHE_DURATION = 5 * 60 * 1000; // 5 minutes instead of current duration
const clientDataCache = new Map<number, { data: any; timestamp: number; retryCount: number }>();

// Clear cache on errors to prevent stale data
function clearClientCacheOnError(clientId: number) {
  clientDataCache.delete(clientId);
}
```

### **2. Improved Error Handling and Retry Logic**

```typescript
async function getClientData(clientId: number, componentName: string, retryCount = 0): Promise<{ workout_time: string }> {
  // Check cache first with longer duration
  const cached = clientDataCache.get(clientId);
  if (cached && Date.now() - cached.timestamp < CACHE_DURATION) {
    console.log(`[${componentName}] ‚úÖ Using cached client data for client ${clientId}`);
    return cached.data;
  }

  const operationTimeout = 5000; // Reduced from 8000ms to 5000ms
  const maxRetries = 3; // Increased from 2 to 3
  
  try {
    // Add request deduplication to prevent concurrent requests
    const requestKey = `client_data_${clientId}`;
    
    const { data: clientData, error: clientError } = await Promise.race([
      supabase
        .from('client')
        .select('workout_time')
        .eq('client_id', clientId)
        .single(),
      new Promise<never>((_, reject) => {
        setTimeout(() => {
          reject(new Error(`Client fetch timeout after ${operationTimeout}ms`));
        }, operationTimeout);
      })
    ]);

    if (clientError) {
      // Enhanced error handling
      if (retryCount < maxRetries && (
        clientError.message.includes('timeout') || 
        clientError.message.includes('network') ||
        clientError.message.includes('connection') ||
        clientError.message.includes('fetch')
      )) {
        console.warn(`[${componentName}] Client fetch error, retrying (${retryCount + 1}/${maxRetries}):`, clientError);
        
        // Exponential backoff with jitter
        const baseDelay = 1000 * Math.pow(2, retryCount);
        const jitter = Math.random() * 1000;
        const delay = baseDelay + jitter;
        
        await new Promise(resolve => setTimeout(resolve, delay));
        return getClientData(clientId, componentName, retryCount + 1);
      }
      
      console.warn(`[${componentName}] Client fetch error, using fallback:`, clientError);
      const fallbackData = { workout_time: '08:00:00' };
      clientDataCache.set(clientId, { data: fallbackData, timestamp: Date.now(), retryCount: 0 });
      return fallbackData;
    }

    const result = { workout_time: clientData?.workout_time || '08:00:00' };
    
    // Cache the result with retry count
    clientDataCache.set(clientId, { data: result, timestamp: Date.now(), retryCount: 0 });
    console.log(`[${componentName}] ‚úÖ Cached client data for client ${clientId}`);
    
    return result;
  } catch (error) {
    // Enhanced timeout handling
    if (retryCount < maxRetries && error instanceof Error && (
      error.message.includes('timeout') ||
      error.message.includes('network') ||
      error.message.includes('fetch')
    )) {
      console.warn(`[${componentName}] Client fetch timeout, retrying (${retryCount + 1}/${maxRetries}):`, error);
      
      // Exponential backoff with jitter
      const baseDelay = 1000 * Math.pow(2, retryCount);
      const jitter = Math.random() * 1000;
      const delay = baseDelay + jitter;
      
      await new Promise(resolve => setTimeout(resolve, delay));
      return getClientData(clientId, componentName, retryCount + 1);
    }
    
    console.warn(`[${componentName}] Client fetch failed, using fallback:`, error);
    const fallbackData = { workout_time: '08:00:00' };
    clientDataCache.set(clientId, { data: fallbackData, timestamp: Date.now(), retryCount: retryCount + 1 });
    return fallbackData;
  }
}
```

### **3. Request Deduplication**

To prevent multiple concurrent requests for the same client data:

```typescript
// Request deduplication map
const pendingRequests = new Map<string, Promise<any>>();

async function getClientDataWithDeduplication(clientId: number, componentName: string): Promise<{ workout_time: string }> {
  const requestKey = `client_data_${clientId}`;
  
  // Check if request is already pending
  if (pendingRequests.has(requestKey)) {
    console.log(`[${componentName}] ‚è≥ Request already pending for client ${clientId}, waiting...`);
    return pendingRequests.get(requestKey);
  }
  
  // Create new request
  const requestPromise = getClientData(clientId, componentName);
  pendingRequests.set(requestKey, requestPromise);
  
  try {
    const result = await requestPromise;
    return result;
  } finally {
    // Clean up pending request
    pendingRequests.delete(requestKey);
  }
}
```

### **4. Circuit Breaker Pattern**

Implement a circuit breaker to prevent cascading failures:

```typescript
class CircuitBreaker {
  private failures = 0;
  private lastFailureTime = 0;
  private state: 'CLOSED' | 'OPEN' | 'HALF_OPEN' = 'CLOSED';
  
  private readonly failureThreshold = 5;
  private readonly timeout = 30000; // 30 seconds
  
  async execute<T>(operation: () => Promise<T>): Promise<T> {
    if (this.state === 'OPEN') {
      if (Date.now() - this.lastFailureTime > this.timeout) {
        this.state = 'HALF_OPEN';
      } else {
        throw new Error('Circuit breaker is OPEN');
      }
    }
    
    try {
      const result = await operation();
      this.onSuccess();
      return result;
    } catch (error) {
      this.onFailure();
      throw error;
    }
  }
  
  private onSuccess() {
    this.failures = 0;
    this.state = 'CLOSED';
  }
  
  private onFailure() {
    this.failures++;
    this.lastFailureTime = Date.now();
    
    if (this.failures >= this.failureThreshold) {
      this.state = 'OPEN';
    }
  }
}

const clientDataCircuitBreaker = new CircuitBreaker();
```

### **5. Optimized Save Function**

Update the save function to handle timeouts more gracefully:

```typescript
async function savePlanToSchedulePreview(planWeek: TableWeekDay[], clientId: number, planStartDate: Date) {
  console.log(`[savePlanToSchedulePreview] üöÄ ENHANCED SAVE FUNCTION - Starting save for client ${clientId}`);
  
  const startTime = performance.now();
  const componentName = 'savePlanToSchedulePreview';
  
  try {
    // Use circuit breaker for client data fetch
    const clientData = await clientDataCircuitBreaker.execute(async () => {
      return await getClientDataWithDeduplication(clientId, componentName);
    });
    
    const for_time = clientData.workout_time;
    const workout_id = uuidv4();
    
    // Build the payload using the helper
    const rows = buildSchedulePreviewRows(planWeek, clientId, for_time, workout_id);
    
    if (rows.length === 0) {
      console.warn(`[${componentName}] ‚ö†Ô∏è No rows to save for client ${clientId}`);
      return { success: true, message: 'No data to save' };
    }
    
    // Get the date range for this week
    const firstDate = planWeek[0]?.date;
    const lastDate = planWeek[planWeek.length - 1]?.date;
    
    if (!firstDate || !lastDate) {
      return { success: false, error: 'Invalid date range' };
    }
    
    // Get existing preview data with timeout
    const existingDataPromise = supabase
      .from('schedule_preview')
      .select('*')
      .eq('client_id', clientId)
      .eq('type', 'workout')
      .gte('for_date', firstDate)
      .lte('for_date', lastDate);
    
    const existingDataTimeoutPromise = new Promise<never>((_, reject) => {
      setTimeout(() => {
        reject(new Error('Existing data fetch timeout after 10000ms'));
      }, 10000);
    });
    
    const { data: existingData, error: existingError } = await Promise.race([
      existingDataPromise,
      existingDataTimeoutPromise
    ]);
    
    if (existingError) {
      console.warn(`[${componentName}] ‚ö†Ô∏è Existing data fetch failed, proceeding with insert only:`, existingError);
    }
    
    // Process updates and inserts
    const recordsToUpdate = [];
    const recordsToInsert = [];
    
    rows.forEach((newRow) => {
      const existingRow = existingData?.find((existing: any) => 
        existing.client_id === newRow.client_id &&
        existing.for_date === newRow.for_date &&
        existing.type === newRow.type
      );
      
      if (existingRow) {
        recordsToUpdate.push({
          id: existingRow.id,
          ...newRow
        });
      } else {
        recordsToInsert.push(newRow);
      }
    });
    
    console.log(`[${componentName}] üìä Prepared ${recordsToUpdate.length} updates and ${recordsToInsert.length} inserts`);
    
    // Execute operations with timeout protection
    const operationPromises = [];
    
    // Update existing records
    if (recordsToUpdate.length > 0) {
      for (const record of recordsToUpdate) {
        const { id, ...updateData } = record;
        operationPromises.push(
          supabase
            .from('schedule_preview')
            .update(updateData)
            .eq('id', id)
        );
      }
    }
    
    // Insert new records
    if (recordsToInsert.length > 0) {
      operationPromises.push(
        supabase
          .from('schedule_preview')
          .insert(recordsToInsert)
      );
    }
    
    // Execute all operations with timeout
    const operationTimeoutPromise = new Promise<never>((_, reject) => {
      setTimeout(() => {
        reject(new Error('Database operations timeout after 15000ms'));
      }, 15000);
    });
    
    const results = await Promise.race([
      Promise.all(operationPromises),
      operationTimeoutPromise
    ]);
    
    // Check for errors
    const errors = results.filter(result => result.error);
    if (errors.length > 0) {
      console.error(`[${componentName}] ‚ùå Database operation errors:`, errors);
      return { success: false, error: `Database operations failed: ${errors.map(e => e.error?.message).join(', ')}` };
    }
    
    const endTime = performance.now();
    console.log(`[${componentName}] ‚úÖ Save completed successfully in ${(endTime - startTime).toFixed(2)}ms`);
    
    return { success: true };
    
  } catch (error) {
    const endTime = performance.now();
    console.error(`[${componentName}] ‚ùå Save failed after ${(endTime - startTime).toFixed(2)}ms:`, error);
    
    return { 
      success: false, 
      error: error instanceof Error ? error.message : 'Unknown error occurred'
    };
  }
}
```

## üìä **Expected Results After Fix**

1. **Reduced Timeout Occurrences**: Better retry logic and circuit breaker prevent cascading failures
2. **Improved Performance**: Request deduplication prevents unnecessary concurrent requests
3. **Better Error Handling**: More graceful fallbacks and clearer error messages
4. **Enhanced Reliability**: Circuit breaker prevents system overload during issues
5. **Better User Experience**: Faster response times and more reliable saves

## üéØ **Implementation Priority**

1. **High Priority**: Enhanced error handling and retry logic
2. **Medium Priority**: Request deduplication
3. **Low Priority**: Circuit breaker pattern (can be added later if needed)

## üìù **Summary**

The timeout issues are not due to fundamental problems with the database or schema, but rather due to network conditions and resource contention. The comprehensive fix addresses these issues through:

- **Better caching strategy**
- **Enhanced retry logic with exponential backoff**
- **Request deduplication**
- **Circuit breaker pattern**
- **Improved timeout handling**

This should significantly reduce the occurrence of timeout issues and provide a more robust Save Changes functionality.
